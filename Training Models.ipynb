{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKF_final_test = pd.read_csv('./AKF_final_test.csv.gz', compression='gzip')\n",
    "AKF_final_test_KNN = pd.read_csv('./AKF_KNN_final_test.csv.gz', compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadm_features = AKF_final_test.loc[:, '(\\'min\\', 50861)' : '(\\'above_max\\', 51498)']\n",
    "hadm_target = AKF_final_test.loc[:, 'AKF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatinine - 50912\n",
    "\n",
    "hadm_features = hadm_features.loc[:, ['(\\'max\\', 50912)',  '(\\'above_max\\', 50912)', '(\\'mean\\', 50912)',  '(\\'abn_percent\\', 50912)']]\n",
    "# hadm_features = AKF_final_test.loc[:, '(\\'min\\', 50861)' : '(\\'above_max\\', 51498)']\n",
    "# hadm_target = AKF_final_test.loc[:, 'AKF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(hadm_features, hadm_target, stratify=hadm_target, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Optional cell for NearMiss\n",
    "# # from imblearn.under_sampling import NearMiss\n",
    "# # from imblearn.over_sampling import SMOTE\n",
    "# # sm = SMOTE()\n",
    "# # nm = NearMiss()\n",
    "# # X, y = nm.transform(hadm_features, hadm_target)\n",
    "# # hadm_features, hadm_target = X, y\n",
    "\n",
    "# # Simulate NearMiss\n",
    "# train_data = pd.concat([X_train, y_train], axis=1)\n",
    "# test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# AKF = train_data[train_data.AKF==1]\n",
    "# non_AKF = train_data[train_data.AKF==0]\n",
    "\n",
    "# non_AKF = non_AKF.sample(n=len(AKF))\n",
    "\n",
    "# undersampled_train_data = pd.concat([AKF, non_AKF], axis=0)\n",
    "# undersampled_train_data = undersampled_train_data.sample(frac=1)\n",
    "\n",
    "# X_train = undersampled_train_data.drop('AKF', axis=1)\n",
    "# y_train = undersampled_train_data['AKF']\n",
    "\n",
    "# X_test = test_data.drop('AKF', axis=1)\n",
    "# y_test = test_data['AKF']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.04 s, sys: 831 ms, total: 5.87 s\n",
      "Wall time: 1.14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.901967213114754"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# L2\n",
    "params_log = [ {'C':np.logspace(-4, 3, 20)} ]\n",
    "logReg = LogisticRegression(max_iter = 2000, class_weight = \"balanced\")\n",
    "\n",
    "# # L1\n",
    "# params_log = [ {'C':np.logspace(-4, -1, 20)} ]\n",
    "# logReg = LogisticRegression(penalty = 'l1', max_iter = 2000, class_weight = \"balanced\", solver = 'liblinear')\n",
    "\n",
    "grid_log = GridSearchCV(estimator = logReg, param_grid = params_log, cv = 5)\n",
    "grid_log.fit(X_train, y_train)\n",
    "grid_log.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.4832930238571752}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_log.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"('max', 50912)\", 5.22565703560579),\n",
       " (\"('above_max', 50912)\", -3.717912049584424),\n",
       " (\"('mean', 50912)\", -1.3959909911841113),\n",
       " (\"('abn_percent', 50912)\", 1.243555740041327)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X_train.columns, grid_log.best_estimator_.coef_[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 90.07%\n",
      "_______________________________________________\n",
      "Classification Report:\tPrecision Score: 61.58%\n",
      "\t\t\tRecall Score: 76.76%\n",
      "\t\t\tF1 score: 68.34%\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[807  68]\n",
      " [ 33 109]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = grid_log.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(\"Classification Report:\", end='')\n",
    "print(f\"\\tPrecision Score: {precision_score(y_test, pred) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tRecall Score: {recall_score(y_test, pred) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tF1 score: {f1_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "import sklearn.model_selection as ms\n",
    "\n",
    "randomForest = ensemble.RandomForestClassifier(class_weight = \"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.98 s, sys: 764 ms, total: 8.74 s\n",
      "Wall time: 44.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(class_weight='balanced'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': range(1, 20),\n",
       "                         'n_estimators': range(10, 110, 10)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid_para_forest = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(1, 20),\n",
    "    'n_estimators': range(10, 110, 10)\n",
    "}\n",
    "\n",
    "grid_search_forest = ms.GridSearchCV(randomForest, grid_para_forest, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"('max', 50912)\", 0.3945927536480366),\n",
       " (\"('above_max', 50912)\", 0.3942217221682857),\n",
       " (\"('abn_percent', 50912)\", 0.15528583495965484),\n",
       " (\"('mean', 50912)\", 0.05589968922402293)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get most important features\n",
    "tree_final = grid_search_forest.best_estimator_\n",
    "feature_importance = tree_final.feature_importances_\n",
    "feature_importance = list(zip(X_train.columns, feature_importance))\n",
    "\n",
    "feature_importance.sort(key = lambda x: x[1], reverse = True)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 3, 'n_estimators': 30}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9059016393442623"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_forest.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is: 0.90689\n",
      "The test     error is: 0.90855\n"
     ]
    }
   ],
   "source": [
    "print(\"The training error is: %.5f\" % (grid_search_forest.score(X_train, y_train)))\n",
    "print(\"The test     error is: %.5f\" % (grid_search_forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 90.86%\n",
      "_______________________________________________\n",
      "Classification Report:\tPrecision Score: 63.10%\n",
      "\t\t\tRecall Score: 83.10%\n",
      "\t\t\tF1 score: 71.73%\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[806  69]\n",
      " [ 24 118]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_predictions = tree_final.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, rf_predictions) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(\"Classification Report:\", end='')\n",
    "print(f\"\\tPrecision Score: {precision_score(y_test, rf_predictions) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tRecall Score: {recall_score(y_test, rf_predictions) * 100:.2f}%\")\n",
    "print(f\"\\t\\t\\tF1 score: {f1_score(y_test, rf_predictions) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, rf_predictions)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
